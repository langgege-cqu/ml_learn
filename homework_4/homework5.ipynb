{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (c1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (c2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (c3): Sequential(\n",
      "    (0): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
      "    (1): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_clases=10):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 120, kernel_size=5),\n",
    "            nn.BatchNorm2d(120),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(84, 10),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "    # 正向传播，反向传播通过loss.backward()\n",
    "    def forward(self, x):\n",
    "        out = self.c1(x)\n",
    "        out = self.c2(out)\n",
    "        out = self.c3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = Net().cuda()\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "16\n",
      "torch.Size([6, 1, 5, 5])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "accuracy: 0.9879351265822784\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def load_data():\n",
    "    train_dataset = tv.datasets.MNIST(\"./\", download=True, transform=tv.transforms.ToTensor())\n",
    "    test_dataset = tv.datasets.MNIST(\"./\", train=False, transform=tv.transforms.ToTensor())\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=128)\n",
    "    return trainloader,testloader\n",
    "\n",
    "# 网络训练\n",
    "def trans(num_epochs):\n",
    "    # 网络训练\n",
    "    # 交叉熵代价函数和优化器\n",
    "    lossfunc = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    # params (iterable) – 待优化参数的iterable或者是定义了参数组的dict\n",
    "    # lr (float, 可选) – 学习率（默认：1e-3）\n",
    "    # betas (Tuple[float, float], 可选) – 用于计算梯度以及梯度平方的运行平均值的系数（默认：0.9，0.999）\n",
    "    # eps (float, 可选) – 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）\n",
    "    # weight_decay (float, 可选) – 权重衰减（L2惩罚）（默认: 0）\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i,(data, label) in enumerate(trainloader):\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            model.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = lossfunc(outputs, label)\n",
    "            # 计算梯度\n",
    "            loss.backward()\n",
    "            # 权重参数更新\n",
    "            optimizer.step()\n",
    "            '''\n",
    "            # 训练100张计算准确率\n",
    "            if i % 100 == 0:\n",
    "                print(i, acc(outputs, label))\n",
    "            '''\n",
    "\n",
    "def test_model(model, testloader):\n",
    "    result = []\n",
    "    for i,(data,label) in enumerate(testloader):\n",
    "        data,label = data.cuda(),label.cuda()\n",
    "        outputs = model(data)\n",
    "        result.append(acc(outputs,label))\n",
    "        count = i\n",
    "    result = sum(result) / len(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 准确率\n",
    "def acc(outputs,label):\n",
    "    _,data = torch.max(outputs,dim=1)\n",
    "    return torch.mean((data.float()==label.float()).float()).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 超参数,训练10轮\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "trainloader, testloader = load_data()\n",
    "trans(num_epochs)\n",
    "res = test_model(model, testloader)\n",
    "print('accuracy:', res)\n",
    "# 网络保存\n",
    "torch.save(model.state_dict(), \"./base.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 输出32*32\n",
    "## c1:6个5*5步长为1的卷积核 --> 输出6个((32-5)/1+1) = 28,即6个28*28特征图\n",
    "## c2:2*2池化 --> 输出6个 14*14特征图\n",
    "## c3:16个5*5卷积核卷积 --> 输出16个((14-5))/1 + 1) = 10,即16个10*10特征图\n",
    "## c3:2*2池化 --> 输出16个 5*5特征图\n",
    "## fc1:120个5*5步长为1的卷积核 --> 输出(5x5x16+1)x120 = 48120个连接\n",
    "## fc2:全连接 训练参数：84*(120+1)=10164\n",
    "## output:全连接10个节点代表0-10\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}