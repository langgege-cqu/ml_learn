{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Southern University of Science and Technology-Department of Computer Science and Engineering\n",
    "\n",
    "Course: Machine Learning(CS 405)-Professor: Qi Hao\n",
    "\n",
    "## Homework #2\n",
    "#### Due date: October, 7th, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries that you might require.\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will implement the KNN algorithm for the breast cancer dataset. Refer to the pdf and the following functions for the instructions. Complete all the functions as indicated below. The four functions would be autograded as mentioned in the pdf."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "3 neighbor-L1-accurcy 0.92\n",
      "3 neighbor-L2-accurcy 0.93\n",
      "3 neighbor-L-inf-accurcy 0.92\n",
      "5 neighbor-L1-accurcy 0.92\n",
      "5 neighbor-L2-accurcy 0.94\n",
      "5 neighbor-L-inf-accurcy 0.91\n",
      "7 neighbor-L1-accurcy 0.92\n",
      "7 neighbor-L2-accurcy 0.93\n",
      "7 neighbor-L-inf-accurcy 0.92\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "3 neighbor-L1-accurcy 0.927536231884058\n",
      "3 neighbor-L2-accurcy 0.9130434782608695\n",
      "3 neighbor-L-inf-accurcy 0.9130434782608695\n",
      "5 neighbor-L1-accurcy 0.927536231884058\n",
      "5 neighbor-L2-accurcy 0.9420289855072463\n",
      "5 neighbor-L-inf-accurcy 0.927536231884058\n",
      "7 neighbor-L1-accurcy 0.9420289855072463\n",
      "7 neighbor-L2-accurcy 0.9130434782608695\n",
      "7 neighbor-L-inf-accurcy 0.9130434782608695\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task 1: Classification\n",
    "\n",
    "Please implement KNN for K: 3, 5, and 7 with the following norms:\n",
    "L1\n",
    "L2\n",
    "L-inf\n",
    "\"\"\"\n",
    "\n",
    "# Read data (Breast Cancer Dataset). Remember to comment out the code not contained in a function.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "\n",
    "X = breast['data']\n",
    "y = breast['target']\n",
    "\n",
    "np.random.seed(100)\n",
    "p = np.random.permutation(len(X))\n",
    "X, y = X[p], y[p]\n",
    "\n",
    "X_train, y_train = X[:400], y[:400]\n",
    "X_val, y_val = X[400:500], y[400:500]\n",
    "X_test, y_test = X[500:], y[500:]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train, X_val, X_test = min_max_scaler.fit_transform(X_train), min_max_scaler.fit_transform(X_val), min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "def distanceFunc(metric_type, vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes the distance between two d-dimension vectors. \n",
    "    \n",
    "    Please DO NOT use Numpy's norm function when implementing this function. \n",
    "    \n",
    "    Args:\n",
    "        metric_type (str): Metric: L1, L2, or L-inf\n",
    "        vec1 ((d,) np.ndarray): d-dim vector\n",
    "        vec2 ((d,)) np.ndarray): d-dim vector\n",
    "    \n",
    "    Returns:\n",
    "        distance (float): distance between the two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    diff = vec1 - vec2\n",
    "    diff = np.array([abs(x) for x in diff])\n",
    "    #print(len(diff))\n",
    "    if metric_type == \"L1\":\n",
    "        distance = sum(diff)\n",
    "\n",
    "    if metric_type == \"L2\":\n",
    "        distance = np.sqrt(sum(diff * diff)) \n",
    "        \n",
    "    if metric_type == \"L-inf\":\n",
    "        distance = max([x for x in diff])\n",
    "        \n",
    "    return distance\n",
    "\n",
    "\n",
    "def computeDistancesNeighbors(K, metric_type, X_train, y_train, sample):\n",
    "    \"\"\"\n",
    "    Compute the distances between every datapoint in the train_data and the \n",
    "    given sample. Then, find the k-nearest neighbors.\n",
    "    \n",
    "    Return a numpy array of the label of the k-nearest neighbors.\n",
    "    \n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        sample ((p,) np.ndarray): Single sample whose distance is to computed with every entry in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # You will also call the function \"distanceFunc\" here\n",
    "    # Complete this function\n",
    "    neighbors = []\n",
    "    neighbors_distance = []\n",
    "    for i in range(len(X_train)):\n",
    "        curr_distance = distanceFunc(metric_type, X_train[i], sample)\n",
    "        neighbors_distance.append(curr_distance)\n",
    "    neighbors_distance = np.array(neighbors_distance)\n",
    "    sortedDistIndicies = neighbors_distance.argsort()\n",
    "    count = 0\n",
    "    while count < K:\n",
    "        neighbors.append(y_train[sortedDistIndicies[count]])\n",
    "        count += 1\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def Majority(neighbors):\n",
    "    \"\"\"\n",
    "    Performs majority voting and returns the predicted value for the test sample.\n",
    "    \n",
    "    Since we're performing binary classification the possible values are [0,1].\n",
    "    \n",
    "    Args:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "        \n",
    "    Returns:\n",
    "        predicted_value (int): predicted label for the given sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # Performs majority voting\n",
    "    # Complete this function\n",
    "    value_0, value_1 = 0, 0\n",
    "    for label in neighbors:\n",
    "        if label:\n",
    "            value_1 += 1\n",
    "        else:\n",
    "            value_0 += 1\n",
    "    predicted_value = 0 if value_0 > value_1 else 1\n",
    "    return predicted_value\n",
    "\n",
    "\n",
    "def KNN(K, metric_type, X_train, y_train, X_val):\n",
    "    \"\"\"\n",
    "    Returns the predicted values for the entire validation or test set.\n",
    "    \n",
    "    Please DO NOT use Scikit's KNN model when implementing this function. \n",
    "\n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        X_val ((n, p) np.ndarray): Validation or test data\n",
    "        \n",
    "    Returns:\n",
    "        predicted_values (list): output for every entry in validation/test dataset \n",
    "    \"\"\"\n",
    "    \n",
    "    # Complete this function\n",
    "    # Loop through the val_data or the test_data (as required)\n",
    "    # and compute the output for every entry in that dataset  \n",
    "    # You will also call the function \"Majority\" here\n",
    "    predictions = []\n",
    "    for i in range(len(X_val)):\n",
    "        neighbors_label = computeDistancesNeighbors(K, metric_type, X_train, y_train, X_val[i])\n",
    "        predictions.append(Majority(neighbors_label))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluation(predicted_values, actual_values):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the given datapoints.\n",
    "    \n",
    "    Args:\n",
    "        predicted_values ((n,) np.ndarray): Predicted values for n samples\n",
    "        actual_values ((n,) np.ndarray): Actual values for n samples\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): accuracy\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in range(len(predicted_values)):\n",
    "        if predicted_values[i] == actual_values[i]:\n",
    "            count += 1\n",
    "        \n",
    "    return count / len(predicted_values)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Calls the above functions in order to implement the KNN algorithm.\n",
    "    \n",
    "    Test over the following range K = 3,5,7 and all three metrics. \n",
    "    In total you will have nine combinations to try.\n",
    "    \n",
    "    PRINTS out the accuracies for the nine combinations on the validation set,\n",
    "    and the accuracy on the test set for the selected K value and appropriate norm.\n",
    "    \n",
    "    REMEMBER: You have to report these values by populating the Table 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Complete this function\n",
    "    \n",
    "    K = [3,5,7]\n",
    "    norm = [\"L1\", \"L2\", \"L-inf\"]\n",
    "    acc_validation = []\n",
    "    print(\"<<<<VALIDATION DATA PREDICTIONS>>>>\")\n",
    "    for k in K:\n",
    "        for nor in norm:\n",
    "            acc = evaluation(KNN(k,nor,X_train,y_train,X_val), y_val)\n",
    "            print(k,'neighbor-' + nor + '-accurcy',acc)\n",
    "            acc_validation.append(acc)\n",
    "    \n",
    "    print(\"<<<<TEST DATA PREDICTIONS>>>>\")\n",
    "    for k in K:\n",
    "        for nor in norm:\n",
    "            acc = evaluation(KNN(k,nor,X_train,y_train,X_test), y_test)\n",
    "            print(k,'neighbor-' + nor + '-accurcy',acc)\n",
    "            acc_validation.append(acc)\n",
    "    ## Complete\n",
    "    \n",
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uncomment the code below to run the main function (Remember to recomment the code before submitting)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Finally, call the main function\n",
    "# main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Answer the following questions here:\n",
    "\n",
    "1. How could having a larger dataset influence the performance of KNN?\n",
    "\n",
    "2. Tabulate your results from `main()` in the table provided.\n",
    "\n",
    "3. Finally, mention the best K and the norm combination you have settled upon and report the accuracy on the test set using that combination."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.k和距离的计算\n",
    "# 2.\n",
    "## k/dist         3        5       7\n",
    "## l1            0.927    0.927   0.942\n",
    "## l2            0.913    0.942   0.913\n",
    "## l-inf         0.913    0.927   0.913\n",
    "# 3. k = 5, l2 最好accuracy = 0.942"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}